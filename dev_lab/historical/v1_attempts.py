"""
è¿™ä¸ªæ–‡ä»¶è®°å½•ä¸€äº›åœ¨ä»£ç çš„ç¼–å†™è¿‡ç¨‹ä¸­ï¼Œæ²¡æœ‰æœ€åè¢«é‡‡çº³çš„éƒ¨åˆ†ï¼Œä½œä¸ºå¤‡ä»½
"""

# è°ƒè¯•ä»£ç éƒ¨åˆ†

    """ ==================== æ·»åŠ çš„è°ƒè¯•ä»£ç å¼€å§‹ ====================
    # å°† feat_maps çš„è¯¦ç»†ä¿¡æ¯ä¿å­˜åˆ° feat_maps_debug.txt æ–‡ä»¶ä¸­
    with open("feat_maps_debug_v1.txt", "w", encoding="utf-8") as f:
        f.write("--- Feat Maps Debug Info ---\n\n")
        f.write(f"Length of feat_maps: {len(feat_maps)}\n")
        f.write(f"Type of feat_maps: {type(feat_maps)}\n\n")

        if len(feat_maps) > 0:
            f.write(f"--- Details of the first element ---\n")
            f.write(f"Type of first element: {type(feat_maps[0])}\n")
            if isinstance(feat_maps[0], dict):
                f.write(f"Keys in first element: {list(feat_maps[0].keys())}\n")
        else:
            f.write("The feat_maps list is EMPTY.\n")
        
        f.write("\n--- Full content of feat_maps ---\n")
        f.write(str(feat_maps))

    print("[è°ƒè¯•ä¿¡æ¯] feat_maps çš„å†…å®¹å·²ä¿å­˜åˆ° feat_maps_debug_v1.txt æ–‡ä»¶ä¸­ï¼Œè¯·æŸ¥çœ‹ã€‚")
    # ==================== æ·»åŠ çš„è°ƒè¯•ä»£ç ç»“æŸ ==================== """


    # sty_feature, sty_z_enc = feature_extractor(opt.sty, sty_img, feature_dir, model, sampler, ddim_inversion_steps, uc, time_idx_dict, opt.start_step, save_feature_timesteps, ddim_sampler_callback, save_feat=True)

# ä¸»å¾ªç¯

# b. DDIM Inversion æ•è·ç‰¹å¾
                # _ = feature_extractor(purpose='content', model=model, sampler=sampler, uc=uc, time_idx_dict=time_idx_dict, ddim_sampler_callback=ddim_sampler_callback, direct_latent_input=z_0_patch, target_step_num=i)


        # final_wsi_img = Image.fromarray(final_wsi_np) 
        # final_wsi_img.save(os.path.join(opt.out, f"final_decoded_{idx}.tiff"))

# å‡½æ•°éƒ¨åˆ†
# ç‰¹å¾æå– åœ¨ç‰¹å®šçš„æ—¶é—´æ­¥ save_feature_timesteps
def feature_extractor(
    # --- é€šç”¨å‚æ•° ---
    purpose='style', # æ¨¡å¼ ('style' æˆ– 'content')
    model, 
    sampler, 
    uc,
    time_idx_dict, 
    save_feature_timesteps,
    ddim_sampler_callback=None,
    ddim_inversion_steps=50, 
    # --- styleå‚æ•° ---
    img_dir,
    img_name, 
    feature_dir, 
    start_step=49, 
    save_feat=False
    # --- contentå‚æ•° ---
    direct_latent_input: torch.Tensor = None, # ç›´æ¥æ¥æ”¶content
    target_step_num=None,    # ğŸ‘ˆ æŒ‡å®šå•ä¸ªæ—¶é—´æ­¥ï¼ˆå¦‚30ï¼‰ï¼Œé»˜è®¤ä¸ºNoneä¸æå–
    ):

    global feat_maps
    feat_maps = []
    
    img_feature = None
    img_z_enc = None
    feature = None # æŒ‡å®šæ—¶é—´æ­¥çš„ç‰¹å¾

    if purpose == 'content':
        if direct_latent_input is None:
            raise ValueError("For 'content' purpose, provide the latent tensor via 'direct_latent_input'.")
        if target_step_num is None:
            raise ValueError("For 'content' purpose, specify the step number via 'target_step_num'.")
        if not (1 <= target_step_num <= ddim_inversion_steps):
            raise ValueError(f"'target_step_num' must be between 1 and {ddim_inversion_steps}.")

        # 1. è®¡ç®—å¾ªç¯ iå’Œ ç¡®åˆ‡çš„æ—¶é—´æ­¥
        target_timestep_t = time_idx_dict[target_step_index] # å®é™…æ—¶é—´æ­¥ t

        # 2. æ‰§è¡ŒDDIMåæ¼”
        _, _ = sampler.encode_ddim(direct_latent_input.clone(), num_steps=ddim_inversion_steps,
                                            unconditional_conditioning=uc,
                                            end_step=target_step_num,
                                            callback_ddim_timesteps=[target_timestep_t],
                                            img_callback=ddim_sampler_callback)
        
        return None    
    
    elif purpose == 'style':
        img_path = os.path.join(img_dir, img_name)
        init_img = preprocess_img(img_path).to('cuda')
        img_feat_name = os.path.join(feature_dir, os.path.basename(img_name).split('.')[0] + '_sty.pkl')

        # 1. ç›´æ¥åŠ è½½ç‰¹å¾è¿”å› styleå›¾ç‰‡
        if os.path.exists(img_feat_name):
            print(f"[âœ“] Loading style feature from {img_feat_name}")
            with open(img_feat_name, 'rb') as f:
                img_feature = pickle.load(f)
                img_z_enc = torch.clone(img_feature[0]['z_enc'])
            return img_feature, z_enc_startstep

        # 2. è¿›è¡Œddimåæ¼”ï¼Œè·å–ç‰¹å¾å›¾
        init_img = model.get_first_stage_encoding(model.encode_first_stage(init_img))  # [1, 4, 64, 64] z_0
        img_z_enc, _ = sampler.encode_ddim(init_img.clone(), num_steps = ddim_inversion_steps, \
                                            unconditional_conditioning = uc, \
                                            end_step = time_idx_dict[ddim_inversion_steps - 1 - start_step], \
                                            callback_ddim_timesteps = save_feature_timesteps, \
                                            img_callback = ddim_sampler_callback)
        
        img_feature = copy.deepcopy(feat_maps)
        # img_z_enc = feat_maps[0]['z_enc']
        img_z_enc = img_feature[0]['z_enc']


        if save_feat and len(feature_dir) > 0:
            print(f"Saving style feature to {img_feat_name}")
            with open(img_feat_name, 'wb') as f:
                pickle.dump(img_feature, f)

        return img_feature, img_z_enc